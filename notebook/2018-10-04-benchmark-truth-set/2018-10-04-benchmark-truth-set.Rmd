---
layout: default
#title: 
#featimg: 
---

Our benchmark experiment uses paired samples of DNA mixes from the four CEPH/Utah grandparents to model somatic variants.  We refer to such sample pairs as benchmark sample pairs and aim to label as positive those variants therein, which are clearly somatic.  Labeling is done based on gold standard germline variant call sets from the unmixed grandparental DNA, and results in a truth set for each benchmark sample pair.  The truth set contains somatic variants (the positives) distributed into 14 distinct alternative allele frequencies (AAF).  We began our study with benchmark sample pair Mix1A:Mix3A but realized the following shortcomings of the initial design: (1) poor decisions on labeling different types of variants; (2) too many positives; (3) the dependence on AAF could be determined only for recall but not for precision.  Here we revise our design.

## Terms

* *real experiment*: a design using a NeuN+ *case sample* and muscle *control sample*
  * I suggest the name *control sample* instead of *reference sample* because "reference" already qualifies the GRCh37decoy reference genome
* *benchmark experiment*: designed to model a real experiment under known somatic variants and other controlled conditions
* *initial benchmark design* (see below) was used for the analysis presented by Chaggai on the BSMN call on 10/4/2018
* *individual sample*: genomic DNA of one of the four CEPH/Utah grandparents (NA12889, NA12890, NA12891, NA12892)
* *(benchmark) mix*: a mixture $$m \in \{\mathrm{Mix}1, \mathrm{Mix}2, \mathrm{Mix}3 \}$$ of individual samples NA12889, NA12890, NA12891, NA12892 in 3 different proportions:
  * Mix1 4:8:16:72
  * Mix2 2:4:8:86
  * Mix3 0:0:0:100
* *mix replicate*: each mix was aliquoted and sequenced in three replicates A, B, C
* *benchmark sample pair*: a pair of possibly identical mix replicates; the initial design used Mix1A:Mix3A as case and control sample, respectively
* *callset*: records in a *filtered* or *unfiltered* VCF file
* *benchmark somatic callset* is generated by---typically---a somatic caller based on a benchmark sample pair
* *benchmark germline callset*: filtered callset generated by a germline caller (strelka or strelka2) based on an individual sample
  * *Illumina germline callset* were downloaded from [Illumina's BaseSpace](https://basespace.illumina.com/home/index)
  * *Chesslab germline callset* were generated in our lab from our sequencing data
* *benchmark variant*: a variant in any of the benchmark germline callsets
* *truth table*: constructed by Chaggai from benchmark variants of all four pairs of benchmark germline callsets (each callset pair is Illumina/Chesslab)
  * only snps and mnps (single and multiple nucleotide polymorphisms)
  * rows: benchmark variants
  * columns: individual genotypes as well as alternative nucleotide allele frequencies, AAF, for each nucleotide and benchmark sample pair
* *benchmark variant type*: based on the truth table and a given benchmark sample pair; for the initial design (Mix1:Mix3 sample pair) four types were defined:
  1. *conflicting genotype* for a given individual there is inconsistency in genotype between the Illumina and Chesslab germline callset
  1. *100% alternative allele* all individuals have the same AA genotype, while the reference genome (GRCh37) has RR, where A: alternative allele, R: reference allele
  1. *heterozygous control sample* the control sample (Mix3 = NA12892) has RA genotype
  1. *homozygous control sample* the control sample (Mix3 = NA12892) has RR or AA genotype
* *labeling*: assigning either *positive* or *negative* label to (candidate) variants in a given benchmark sample pair
  * in the present context positive labels somatic variants and negative anything but those note that both positives and negatives may be germline variants;
  * in the truth table benchmark variants are labeled by considering which benchmark variant types represent somatic variants; the positively labeled variants are the *(actual) positives* in the sense of ground truth
  * in the context of a benchmark somatic callset labeling is nothing but calling and filtering; these *called positives* or simply *calls* are either *true positives* or *false positives*; the (actual) positives not called are *false negatives*
* *precision* is defined based on the expected number of true and false positives as $$\mathrm{E} [N_\mathrm{TP}] / (\mathrm{E} [N_\mathrm{TP}] + \mathrm{E} [N_\mathrm{FP}])$$
* *recall* is defined based on the expected number of true positives and false negatives as $$\mathrm{E} [N_\mathrm{TP}] / (\mathrm{E} [N_\mathrm{TP}] + \mathrm{E} [N_\mathrm{FN}])$$
* *precision-recall curve* is the set of precision and recall values evaluated at an ordered sequence of filter settings; such an ordered sequence is given by the probability that a call is true, estimated by VariantMetaCaller

## Initial design

|-------------------------------------------------------------------------------
|variant type in benchmark sample pair |label (is somatic variant?)|filter out?|
|-------------------------------------------------------------------------------
|conflicting genotype                  |    negative        |    no            |
|100% alternative allele               |    negative        |    no            |
|heterozygous control sample           |    positive        |    no            |
|homozygous control sample             |    positive        |    no            |
|-------------------------------------------------------------------------------

## New design

|-------------------------------------------------------------------------------
|variant type in benchmark sample pair |label (is somatic variant?)|filter out?|
|-------------------------------------------------------------------------------
|conflicting genotype                  |    negative        |    yes           |
|100% alternative allele               |    negative        |    no            |
|heterozygous control sample           |    negative        |    no            |
|homozygous control sample             |    positive        |remove some\*     |
|-------------------------------------------------------------------------------

### The realistic number of somatic variants

We can regard the remaining (modeled) clearly somatic variants as the set of actual positives but this set is orders of magnitude larger than what we expect, which leads to highly inflated precision.  Therefore we discard also most of these somatic variants to match the size of the positive set in our benchmark to that expected in real tissue pairs.

Excluding the variants (1) for which NA12892/Mix3 is heterozygous as well as (2) those for which our variant calling results contradict Illumina's results retains clearly somatic variants.  But these are too many: Chr22 alone contains 42289 of them.  On the other hand, single cell sequencing studies estimated, for the whole genome, 2000 or even just 100 somatic mutations per cell in average; see [Lodato 2015](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4664477/) and [Hazen 2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4795965/), respectively.  It is not straight forward to establish how the expected number of mutations $$\mathrm{E} N_\mathrm{scell}$$ per cell determines the expected number of mutations $$\mathrm{E} N_\mathrm{paired}$$ in our paired sample bulk sequencing design.  However, it is safe to assume that $$\mathrm{E} N_\mathrm{scell} < \mathrm{E} N_\mathrm{paired}$$ because some of the cells in the tissue sample may contain somatic mutations that other cells lack and vice versa.

### Dependence of precision on alternative allele frequency

Conditioning recall and precision on AAF requires different kind of information.

1. recall: AAF for each modeled somatic variant; available
1. precision: AAF for each call; unavailable

The AAF for each call is unavailable in the initial design either because if the call is true the caller cannot provide a precise and unbiased estimate for AAF and if the call is false there is no variant thus AAF is undefined.  But the design of the benchmark experiment can be modified to fix that.  One needs to remove all variants but those whose AAF equals to a certain value.

## Design

Suppose $$\mathrm{E} N_\mathrm{paired} = 1000$$ is realistic for the whole genome.  The expected number of positives in the unrealistic initial design:

```{r}
len <- list(genome = 3153681224, chr22 = 51304566)
npos <- list(genome = NA, chr22 = 42289)
(npos$genome <- npos$chr22 * len$genome / len$chr22)
```

So we have `r npos$genome` positives instead of only 1000 positives, which means we need to retain only a fraction of `r 1000 / npos$genome` of them.  Let's round it to $$4 \times 10^{-4}$$!

It may be worth trying also $$\mathrm{E} N_\mathrm{paired} = 10000$$ and 100000, which correspond to retaining fractions of $$4 \times 10^{-3}$$ and $$4 \times 10^{-2}$$, respectively.

1. let $$\mathrm{AAF} = f$$; note that $$f\in E$$, the set of possible AAFs given the DNA mix
1. remove variants for which NA12892/Mix3 is heterozygous
1. remove variants for which our variant calling results contradict Illumina's results
1. remove purely germline variants (the *100% alternative allele variants* in Chaggai's jargon)
1. (optional) remove all variants but those whose AAF equals to $$f$$
1. using the remaining variants randomly retain a fraction of $$4 \times 10^{-2}$$, $$4 \times 10^{-3}$$ and $$4 \times 10^{-4}$$ as actual positives and filter out the rest

## TODOs

1. review Chaggai's truth table and the tools he developed
1. implement the above procedures using `bcftools` or the `vcf` python module.
